{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ba6821-4866-4627-a71a-7f6f1c8954fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Overview:\n",
      "   ID             area_type   availability                  location  \\\n",
      "0   0  Super built-up  Area         19-Dec  Electronic City Phase II   \n",
      "1   1            Plot  Area  Ready To Move          Chikka Tirupathi   \n",
      "2   2        Built-up  Area  Ready To Move               Uttarahalli   \n",
      "3   3  Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
      "4   4  Super built-up  Area  Ready To Move                  Kothanur   \n",
      "\n",
      "        size  society total_sqft  bath  balcony   price  \n",
      "0      2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
      "1  4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      3 BHK      NaN       1440   2.0      3.0   62.00  \n",
      "3      3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      2 BHK      NaN       1200   2.0      1.0   51.00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10656 entries, 0 to 10655\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            10656 non-null  int64  \n",
      " 1   area_type     10656 non-null  object \n",
      " 2   availability  10656 non-null  object \n",
      " 3   location      10655 non-null  object \n",
      " 4   size          10642 non-null  object \n",
      " 5   society       6228 non-null   object \n",
      " 6   total_sqft    10656 non-null  object \n",
      " 7   bath          10591 non-null  float64\n",
      " 8   balcony       10152 non-null  float64\n",
      " 9   price         10656 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 832.6+ KB\n",
      "None\n",
      "\n",
      "Test Data Overview:\n",
      "   ID             area_type   availability            location       size  \\\n",
      "0   0  Super built-up  Area  Ready To Move          Chamrajpet      2 BHK   \n",
      "1   1  Super built-up  Area  Ready To Move  7th Phase JP Nagar      3 BHK   \n",
      "2   2  Super built-up  Area  Ready To Move          Whitefield      3 BHK   \n",
      "3   3        Built-up  Area  Ready To Move           Jalahalli      2 BHK   \n",
      "4   4            Plot  Area  Ready To Move           TC Palaya  1 Bedroom   \n",
      "\n",
      "   society total_sqft  bath  balcony  \n",
      "0      NaN        650   1.0      1.0  \n",
      "1  SrncyRe       1370   2.0      1.0  \n",
      "2  AjhalNa       1725   3.0      2.0  \n",
      "3      NaN       1000   2.0      0.0  \n",
      "4      NaN       1350   1.0      0.0  \n",
      "\n",
      "Avg Rent Data Overview:\n",
      "                        location  avg_2bhk_rent\n",
      "0                Krishnarajapura          11954\n",
      "1                       Sarjapur          45000\n",
      "2  Whitefield Hope Farm Junction          26370\n",
      "3                    Devanahalli          17302\n",
      "4                     Whitefield          14981\n",
      "\n",
      "Distance Data Overview:\n",
      "          location  dist_from_city\n",
      "0       Whitefield            17.3\n",
      "1   Sarjapur  Road            17.2\n",
      "2  Electronic City            18.1\n",
      "3   Kanakpura Road            26.5\n",
      "4      Thanisandra            11.5\n",
      "\n",
      "Missing Values in Train Data:\n",
      "ID                 0\n",
      "area_type          0\n",
      "availability       0\n",
      "location           1\n",
      "size              14\n",
      "society         4428\n",
      "total_sqft         0\n",
      "bath              65\n",
      "balcony          504\n",
      "price              0\n",
      "dtype: int64\n",
      "Validation RMSE: 79.83575479792454\n",
      "Validation R2 Score: 0.6792637748476249\n",
      "Cross-Validation RMSE: 0.17300602390348743\n",
      "XGBoost Validation RMSE: 41.22829394007865\n",
      "Test predictions saved to 'Submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "avg_rent_data = pd.read_csv('avg_rent.csv')\n",
    "dist_data = pd.read_csv('dist_from_city_centre.csv')\n",
    "\n",
    "# Data Exploration\n",
    "print(\"Train Data Overview:\")\n",
    "print(train_data.head())\n",
    "print(train_data.info())\n",
    "\n",
    "print(\"\\nTest Data Overview:\")\n",
    "print(test_data.head())\n",
    "\n",
    "print(\"\\nAvg Rent Data Overview:\")\n",
    "print(avg_rent_data.head())\n",
    "\n",
    "print(\"\\nDistance Data Overview:\")\n",
    "print(dist_data.head())\n",
    "\n",
    "# Data Cleaning\n",
    "# Handle missing values\n",
    "print(\"\\nMissing Values in Train Data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Filling missing numerical columns with median\n",
    "train_data['bath'].fillna(train_data['bath'].median(), inplace=True)\n",
    "train_data['balcony'].fillna(train_data['balcony'].median(), inplace=True)\n",
    "\n",
    "# Dropping 'society' due to high cardinality and missing values\n",
    "train_data.drop(columns=['society'], inplace=True)\n",
    "\n",
    "# Clean 'total_sqft' (convert range values to average)\n",
    "def convert_sqft_to_num(x):\n",
    "    try:\n",
    "        if '-' in x:\n",
    "            vals = x.split('-')\n",
    "            return (float(vals[0]) + float(vals[1])) / 2\n",
    "        elif 'sqft' in x.lower():\n",
    "            return float(x.split(' ')[0])\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "train_data['total_sqft'] = train_data['total_sqft'].apply(convert_sqft_to_num)\n",
    "test_data['total_sqft'] = test_data['total_sqft'].apply(convert_sqft_to_num)\n",
    "\n",
    "# Extract numerical value from 'size'\n",
    "def extract_bhk(x):\n",
    "    try:\n",
    "        return int(x.split(' ')[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "train_data['BHK'] = train_data['size'].apply(extract_bhk)\n",
    "test_data['BHK'] = test_data['size'].apply(extract_bhk)\n",
    "\n",
    "# Drop 'size' as it's redundant now\n",
    "train_data.drop(columns=['size'], inplace=True)\n",
    "test_data.drop(columns=['size'], inplace=True)\n",
    "\n",
    "# Merge additional datasets based on 'location'\n",
    "train_data = train_data.merge(avg_rent_data, on='location', how='left')\n",
    "train_data = train_data.merge(dist_data, on='location', how='left')\n",
    "\n",
    "test_data = test_data.merge(avg_rent_data, on='location', how='left')\n",
    "test_data = test_data.merge(dist_data, on='location', how='left')\n",
    "\n",
    "# Fill missing values in merged columns with median\n",
    "for col in ['avg_2bhk_rent', 'dist_from_city']:\n",
    "    train_data[col].fillna(train_data[col].median(), inplace=True)\n",
    "    test_data[col].fillna(test_data[col].median(), inplace=True)\n",
    "\n",
    "# One-hot encoding for 'area_type' and 'availability'\n",
    "train_data = pd.get_dummies(train_data, columns=['area_type', 'availability'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['area_type', 'availability'], drop_first=True)\n",
    "\n",
    "# Ensure test and train have same columns\n",
    "missing_cols = set(train_data.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    if col != 'price':\n",
    "        test_data[col] = 0\n",
    "test_data = test_data[train_data.columns.drop('price')]\n",
    "\n",
    "# Feature Engineering\n",
    "# Create interaction terms and additional features\n",
    "train_data['price_per_sqft'] = train_data['price'] / train_data['total_sqft']\n",
    "train_data['rent_to_distance'] = train_data['avg_2bhk_rent'] / train_data['dist_from_city']\n",
    "\n",
    "# Ensure price_per_sqft exists in test data\n",
    "test_data['price_per_sqft'] = test_data['total_sqft'] / test_data['avg_2bhk_rent']\n",
    "test_data['price_per_sqft'].fillna(test_data['price_per_sqft'].median(), inplace=True)\n",
    "\n",
    "test_data['rent_to_distance'] = test_data['avg_2bhk_rent'] / test_data['dist_from_city']\n",
    "\n",
    "# Feature and Target Separation\n",
    "X = train_data.drop(columns=['price', 'location'])\n",
    "y = np.log1p(train_data['price'])  # Log-transform the target variable\n",
    "\n",
    "# Fill missing values in X\n",
    "X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Validation\n",
    "val_predictions = np.expm1(best_rf.predict(X_val))  # Reverse log-transform\n",
    "val_actuals = np.expm1(y_val)  # Reverse log-transform\n",
    "print(\"Validation RMSE:\", np.sqrt(mean_squared_error(val_actuals, val_predictions)))\n",
    "print(\"Validation R2 Score:\", r2_score(val_actuals, val_predictions))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Cross-Validation RMSE:\", np.sqrt(-cv_scores.mean()))\n",
    "\n",
    "# Try XGBoost\n",
    "xgb = XGBRegressor(random_state=42, n_estimators=300, max_depth=10, learning_rate=0.1)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_val_predictions = np.expm1(xgb.predict(X_val))\n",
    "print(\"XGBoost Validation RMSE:\", np.sqrt(mean_squared_error(val_actuals, xgb_val_predictions)))\n",
    "\n",
    "# Predictions on Test Data\n",
    "# Fill missing values in numeric columns only\n",
    "numeric_cols = test_data.select_dtypes(include=[np.number]).columns\n",
    "test_data[numeric_cols] = test_data[numeric_cols].fillna(test_data[numeric_cols].median())\n",
    "\n",
    "# Ensure feature alignment for test data\n",
    "missing_cols = set(X_train.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[X_train.columns]\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = np.expm1(best_rf.predict(test_data))\n",
    "\n",
    "# Save predictions to CSV\n",
    "output = pd.DataFrame({'Id': test_data.index, 'Predicted Price': test_predictions})\n",
    "output.to_csv('Submission.csv', index=False)\n",
    "\n",
    "print(\"Test predictions saved to 'Submission.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a99667-ccc4-4e9c-b23f-2248791c4485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
